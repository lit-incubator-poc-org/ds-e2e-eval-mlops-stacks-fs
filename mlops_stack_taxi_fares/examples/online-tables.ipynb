{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdcde834-b622-40fd-8320-c42e4869aec4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Online Feature Store example notebook\n",
    "\n",
    "This notebook illustrates the use of Databricks Feature Store to publish features to Databricks Online Tables for real-time \n",
    "serving and automated feature lookup. The problem is to predict the wine quality using a ML model\n",
    "with a variety of static wine features and a realtime input.\n",
    "\n",
    "This notebook creates an endpoint to predict the quality of a bottle of wine, given an ID and the realtime feature alcohol by volume (ABV).\n",
    "\n",
    "The notebook is structured as follows:\n",
    " \n",
    "1. Prepare the feature table.\n",
    "2. Set up Databricks Online Table.\n",
    "    * This notebook uses Databricks Online Tables. For a list of supported functionality, see the Databricks documentation ([AWS](https://docs.databricks.com/machine-learning/feature-store/online-tables.html) | [Azure](https://learn.microsoft.com/azure/databricks/machine-learning/feature-store/online-tables)).  \n",
    "3. Train and deploy the model.\n",
    "4. Serve realtime queries with automatic feature lookup.\n",
    "5. Clean up.\n",
    "\n",
    "### Data Set\n",
    "\n",
    "This example uses the [Wine Quality Data Set](https://archive.ics.uci.edu/ml/datasets/wine+quality).\n",
    "\n",
    "### Requirements\n",
    "\n",
    "* Serverless Compute ([AWS](https://docs.databricks.com/compute/serverless/index.html) | [Azure](https://learn.microsoft.com/azure/databricks/compute/serverless/index)) (_recommended_)\n",
    "* Classic compute running Databricks Runtime 14.2 for Machine Learning or above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "326b4077-6574-4b16-84a6-00849b08b764",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "656d19cb-e0b6-4b3b-8117-d299f4d95f06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<img src=\"https://docs.databricks.com/_static/images/machine-learning/feature-store/online-tables-nb-diagram.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "31db224e-7eee-418a-a8b4-db81a6e9cb39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-sdk==0.41.0\n",
    "%pip install databricks-feature-engineering==0.8.0\n",
    "%pip install mlflow>=2.9.0\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d5764d8-a202-40ac-a4cb-9f32a35a70ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "## Prepare the feature table\n",
    "\n",
    "Suppose you need to build an endpoint to predict wine quality with just the `wine_id`. This requires a feature table saved in Feature Store where the endpoint can look up features of the wine by the `wine_id`. For the purpose of this demo, we need to prepare this feature table ourselves first. The steps are:\n",
    "\n",
    "1. Load and clean the raw data.\n",
    "2. Separate features and labels.\n",
    "3. Save features into a feature table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c056b1cd-0152-44aa-9ea9-6089c1f0771a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Load and clean the raw data \n",
    "\n",
    "The raw data contains 12 columns including 11 features and the `quality` column. The `quality` column is an integer that ranges from 3 to 8. The goal is to build a model that predicts the `quality` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ccdea09-0fbe-4daf-8eaf-bab43d57f255",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw_data_frame = spark.read.load(\"/databricks-datasets/wine-quality/winequality-red.csv\",format=\"csv\",sep=\";\",inferSchema=\"true\",header=\"true\" )\n",
    "display(raw_data_frame.limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486b0eaf-2385-49d4-bd25-2bdd35e6e2ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Have a look at the size of the raw data.\n",
    "raw_data_frame.toPandas().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30250865-3437-4c33-b6ba-46e5f709d1fd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "There are some problems with the raw data:\n",
    "1. The column names contain space (' '), which is not compatible with Feature Store. \n",
    "2. We need to add ID to the raw data so they can be looked up later by Feature Store.\n",
    "\n",
    "The following cell addresses these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08c73038-0555-4498-b766-9cf741eafce3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Spark Dataframe Preprocessing"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "\n",
    "def addIdColumn(dataframe, id_column_name):\n",
    "    columns = dataframe.columns\n",
    "    new_df = dataframe.withColumn(id_column_name, monotonically_increasing_id())\n",
    "    return new_df[[id_column_name] + columns]\n",
    "\n",
    "def renameColumns(df):\n",
    "    renamed_df = df\n",
    "    for column in df.columns:\n",
    "        renamed_df = renamed_df.withColumnRenamed(column, column.replace(' ', '_'))\n",
    "    return renamed_df\n",
    "\n",
    "\n",
    "# Rename columns so that they are compatible with Feature Store\n",
    "renamed_df = renameColumns(raw_data_frame)\n",
    "\n",
    "# Add id column\n",
    "id_and_data = addIdColumn(renamed_df, 'wine_id')\n",
    "\n",
    "display(id_and_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7aa9c554-7570-4416-9ae9-2998e199907a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's assume that the alcohol by volume (ABV) is a variable that changes over time after the wine is opened. The value will be provided as a real-time input for online inference. \n",
    "\n",
    "Now, split the data into two parts and store only the part with static features to Feature Store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b35f09ab-c062-46d9-80ca-81fa2b42dff2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# wine_id and static features\n",
    "id_static_features = id_and_data.drop('alcohol', 'quality')\n",
    "\n",
    "# wine_id, realtime feature (alcohol), label (quality)\n",
    "id_rt_feature_labels = id_and_data.select('wine_id', 'alcohol', 'quality')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3de5f19b-435e-4608-a2dc-d93a4903ca47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Create a feature table\n",
    "\n",
    "Save the feature data `id_static_features` into a feature table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a6a1b643-daa3-4eaa-8162-f8ac88d0431b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# You must have `CREATE CATALOG` privileges on the catalog.\n",
    "# If necessary, change the catalog and schema name here.\n",
    "username = spark.sql(\"SELECT current_user()\").first()[\"current_user()\"]\n",
    "username = username.split(\".\")[0]\n",
    "catalog_name = username\n",
    "\n",
    "# Fetch the username to use as the schema name.\n",
    "schema_name = \"online_tables\"\n",
    "\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"CREATE DATABASE IF NOT EXISTS {catalog_name}.{schema_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d6b01fc-2180-4019-b0df-148963fb8b37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "\n",
    "wine_table = f\"{catalog_name}.{schema_name}.wine_static_features\"\n",
    "online_table_name = f\"{catalog_name}.{schema_name}.wine_static_features_online\"\n",
    "fe = FeatureEngineeringClient()\n",
    "fe.create_table(\n",
    "    name=wine_table,\n",
    "    primary_keys=[\"wine_id\"],\n",
    "    df=id_static_features,\n",
    "    description=\"id and features of all wine\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "227a25b2-db52-4076-a71d-f937da1e1dbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The feature data has now been stored into the feature table. The next step is to set up a Databricks Online Table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c4b9bf0-7e4f-46f8-a5a4-45418a111048",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Set up Databricks Online Tables\n",
    "\n",
    "You can create an online table from the Catalog Explorer UI, Databricks SDK or Rest API. The steps to use Databricks python SDK are described below. For more details, see the Databricks documentation ([AWS](https://docs.databricks.com/en/machine-learning/feature-store/online-tables.html#create)|[Azure](https://learn.microsoft.com/azure/databricks/machine-learning/feature-store/online-tables#create)). For information about required permissions, see Permissions ([AWS](https://docs.databricks.com/en/machine-learning/feature-store/online-tables.html#user-permissions)|[Azure](https://learn.microsoft.com/azure/databricks/machine-learning/feature-store/online-tables#user-permissions))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bb5f86a3-adae-4f15-891b-2e567b1c2c1f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Databricks Online Table Creation"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.catalog import OnlineTable, OnlineTableSpec, OnlineTableSpecTriggeredSchedulingPolicy\n",
    "\n",
    "workspace = WorkspaceClient()\n",
    "\n",
    "# Create an online table\n",
    "spec = OnlineTableSpec(\n",
    "  primary_key_columns = [\"wine_id\"],\n",
    "  source_table_full_name = wine_table,\n",
    "  run_triggered=OnlineTableSpecTriggeredSchedulingPolicy.from_dict({'triggered': 'true'}),\n",
    "  perform_full_copy=True)\n",
    "\n",
    "online_table = OnlineTable(name=online_table_name, spec=spec)\n",
    "\n",
    "try:\n",
    "  workspace.online_tables.create_and_wait(table=online_table)\n",
    "  \n",
    "except Exception as e:\n",
    "  if \"already exists\" in str(e):\n",
    "    print(f\"Online table {online_table_name} already exists. Not recreating.\")  \n",
    "  else:\n",
    "    raise e\n",
    "\n",
    "pprint(workspace.online_tables.get(online_table_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f620438b-4786-4dbf-8175-64ffcdaeb15b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Train and deploy the model\n",
    "\n",
    "Now, you will train a classifier using features in the Feature Store. You only need to specify the primary key, and Feature Store will fetch the required features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf047801-c3ef-4467-a73a-f94e4a3fb744",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pandas as pd\n",
    "import logging\n",
    "import mlflow.sklearn\n",
    "\n",
    "from databricks.feature_engineering import FeatureLookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaace99e-b63a-4d0f-9a1e-367ec29630ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "First, define a `TrainingSet`. The training set accepts a `feature_lookups` list, where each item represents some features from a feature table in the Feature Store. This example uses `wine_id` as the lookup key to fetch all the features from table `online_feature_store_example.wine_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7d9efa22-b030-440b-ad64-bafaba99b301",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Wine Quality Training Loader"
    }
   },
   "outputs": [],
   "source": [
    "training_set = fe.create_training_set(\n",
    "    df=id_rt_feature_labels,\n",
    "    label='quality',\n",
    "    feature_lookups=[\n",
    "        FeatureLookup(\n",
    "            table_name=f\"{catalog_name}.{schema_name}.wine_static_features\",\n",
    "            lookup_key=\"wine_id\"\n",
    "        )\n",
    "    ],\n",
    "    exclude_columns=['wine_id'],\n",
    ")\n",
    "\n",
    "# Load the training data from Feature Store\n",
    "training_df = training_set.load_df()\n",
    "\n",
    "display(training_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "123b57dd-1dc8-47f7-9619-6dcf89dfe345",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The next cell trains a RandomForestClassifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fe37d30-6f54-4ca3-91ab-c9da60035004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "X_train = training_df.drop('quality').toPandas()\n",
    "y_train = training_df.select('quality').toPandas()\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eb161af-8664-4095-8e0f-7de31a0724f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Save the trained model using `log_model`. `log_model` also saves lineage information between the model and the features (through `training_set`). So, during serving, the model automatically knows where to fetch the features by just the lookup keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8d2d830-3819-43b7-b89e-9c689cce3fd2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Databricks MLflow Model Registration"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "registered_model_name = f\"{catalog_name}.{schema_name}.wine_classifier\"\n",
    "fe.log_model(\n",
    "    model=model,\n",
    "    artifact_path=\"model\",\n",
    "    flavor=mlflow.sklearn,\n",
    "    training_set=training_set,\n",
    "    registered_model_name=registered_model_name\n",
    ")\n",
    "\n",
    "# Get the latest model version\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "versions = client.search_model_versions(f\"name='{registered_model_name}'\")\n",
    "registered_model_version = max(int(v.version) for v in versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00a67ea3-0a6a-43a4-ad5f-f25a3786273b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Serve real-time queries with automatic feature lookup\n",
    "\n",
    "After calling `log_model`, a new version of the model is saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1a76a2f-d922-4aeb-a0da-731829fafdf6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Databricks Wine Classifier Setup"
    }
   },
   "outputs": [],
   "source": [
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.serving import EndpointCoreConfigInput, ServedEntityInput\n",
    "\n",
    "# Create endpoint\n",
    "endpoint_name = f\"{username}_wine_classifier_endpoint\"\n",
    "\n",
    "try:\n",
    "  status = workspace.serving_endpoints.create_and_wait(\n",
    "    name=endpoint_name,\n",
    "    config = EndpointCoreConfigInput(\n",
    "      served_entities=[\n",
    "        ServedEntityInput(\n",
    "            entity_name=registered_model_name,\n",
    "            entity_version=registered_model_version,\n",
    "            scale_to_zero_enabled=True,\n",
    "            workload_size=\"Small\"\n",
    "        )\n",
    "      ]\n",
    "    )\n",
    "  )\n",
    "  print(status)\n",
    "except Exception as e:\n",
    "  if \"already exists\" in str(e):\n",
    "    print(f\"Not creating endpoint {endpoint_name} since it already exists.\")\n",
    "  else:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6e290d3d-ab69-4497-bc10-79e0005d96d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Send a query\n",
    "\n",
    "Now, suppose you opened a bottle of wine and you have a sensor to measure the current ABV from the bottle. Using the model and automated feature lookup with realtime serving, you can predict the quality of the wine using the measured ABV value as the realtime input \"alcohol\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "851f86d5-b2da-4a78-90e4-a55e7db149f3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Databricks Wine Predictor Caller"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow.deployments\n",
    "\n",
    "client = mlflow.deployments.get_deploy_client(\"databricks\")\n",
    "response = client.predict(\n",
    "    endpoint=endpoint_name,\n",
    "    inputs={\n",
    "        \"dataframe_records\": [\n",
    "            {\"wine_id\": 25, \"alcohol\": 7.9},\n",
    "            {\"wine_id\": 25, \"alcohol\": 11.0},\n",
    "            {\"wine_id\": 25, \"alcohol\": 27.9},\n",
    "        ]\n",
    "    },\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd4e1169-b117-4f89-8411-2173e0330909",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Notes on request format and API versions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88c6c9b1-a709-4107-8863-9ed55651ebb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Here is an example of the request format:\n",
    "```\n",
    "{\"dataframe_split\": {\"index\": [0, 1, 2], \"columns\": [\"wine_id\", \"alcohol\"], \"data\": [[25, 7.9], [25, 11.0], [25, 27.9]]}}\n",
    "```\n",
    "\n",
    "Learn more about Databricks Model Serving ([AWS](https://docs.databricks.com/en/machine-learning/model-serving/index.html)|[Azure](https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adc649e0-0418-4ea7-acef-2c376467b51d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Clean up\n",
    "\n",
    "To clean up the resources created by this notebook, follow these steps:\n",
    "\n",
    "1. Delete the Databricks Online Table from Catalog Explorer.  \n",
    "  a. In the left sidebar, click **Catalog**.   \n",
    "  b. Navigate to the online table.  \n",
    "  c. From the kebab menu, select **Delete**.  \n",
    "2. Delete the Serving Endpoint from the **Serving** tab.  \n",
    "  a. In the left sidebar, click **Serving**.  \n",
    "  b. Click the name of the endpoint.  \n",
    "  c. From the kebab menu, select **Delete**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "594ee5b3-8659-4143-ae8c-846ad848ceea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#workspace.serving_endpoints.delete(name=endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6120a22-c3d1-4eee-8550-6338e582fe83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#workspace.online_tables.delete(name=online_table_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "online-tables",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}